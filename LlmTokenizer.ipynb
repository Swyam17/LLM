{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1LN69jcb3PNhL5e5ZILhJvppxBNVlPkPR",
      "authorship_tag": "ABX9TyPJEP6cxHcA1QoTp2XJq9VE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Swyam17/LlmTokenizers/blob/main/LlmTokenizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**S1**: CREATING TOKENS"
      ],
      "metadata": {
        "id": "M_hhTfwfEhHS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "H2e2y7iq3fXx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39fe23a0-9782-4b54-8a34-edb6d440cb5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of character: 20781\n",
            "THE VERDICT\n",
            "June 1908\n",
            "\n",
            "I had always thought Jack Gisburn rather a cheap genius--though a\n",
            "\n",
            "good fell\n"
          ]
        }
      ],
      "source": [
        "with open(\"/content/the-verdict.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    raw_text = f.read()\n",
        "\n",
        "print(\"Total number of character:\", len(raw_text))\n",
        "print(raw_text[:99])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "text = \"Hello, world. This , is a test.\"\n",
        "result = re.split(r'(\\s)',text) # this is used to split the text and even the blank spaces\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5rTGcBxR8b_U",
        "outputId": "7e2cfc6a-0757-4096-f30d-0a6184fc6069"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello,', ' ', 'world.', ' ', 'This', ' ', ',', ' ', 'is', ' ', 'a', ' ', 'test.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "text = \"Hello, world. This , is a test.\"\n",
        "result = re.split(r'([,.]|\\s)',text) # couma is seperate token\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uTrh4D-9AGH",
        "outputId": "3bf12c50-4799-49d3-906a-5ea3e1c440a8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', '', ' ', 'world', '.', '', ' ', 'This', ' ', '', ',', '', ' ', 'is', ' ', 'a', ' ', 'test', '.', '']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = [item for item in result if item.strip()] #removes blank space\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tIxbvVhw_4WO",
        "outputId": "c0677565-3a9d-4ec1-c290-a454b0b79292"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', 'world', '.', 'This', ',', 'is', 'a', 'test', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "REMOVING WHITESPACES OR NOT\n",
        "\n",
        "\n",
        "When developing a simple tokenizer, whether we should encode whitespaces as\n",
        "separate characters or just remove them depends on our application and its\n",
        "requirements. Removing whitespaces reduces the memory and computing\n",
        "requirements. However, keeping whitespaces can be useful if we train models that\n",
        "are sensitive to the exact structure of the text (for example, Python code, which is\n",
        "sensitive to indentation and spacing). Here, we remove whitespaces for simplicity\n",
        "and brevity of the tokenized outputs. Later, we will switch to a tokenization scheme\n",
        "that includes whitespaces."
      ],
      "metadata": {
        "id": "rxYAZRF3AWdD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TOKENIZATION\n",
        "\n",
        "The tokenization scheme we devised above works well on the simple sample text. Let's\n",
        "modify it a bit further so that it can also handle other types of punctuation, such as\n",
        "question marks, quotation marks, and the double-dashes we have seen earlier in the first\n",
        "100 characters of Edith Wharton's short story, along with additional special characters:"
      ],
      "metadata": {
        "id": "rYXvUkgbCRat"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Hello, world. Is this-- a test?\"\n",
        "result = re.split(r'([,.:;?_!\"()\\']|--|\\s)',text)\n",
        "result = [item for item in result if item.strip()] #removes blank space\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSnkGtfPCfjO",
        "outputId": "3511f4b1-dc5b-411c-a14a-58c731fbe300"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hello', ',', 'world', '.', 'Is', 'this', '--', 'a', 'test', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrNepJIVLPfm",
        "outputId": "adadcc03-1d9a-40c3-c028-e64621518276"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessed = re.split(r'([,.:;?_!\"()\\']|--|\\s)', raw_text)\n",
        "preprocessed = [item.strip() for item in preprocessed if item.strip()]\n",
        "print(preprocessed[:30])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UU4XAOa9DfUx",
        "outputId": "703e430b-3e8b-4ce1-83db-3e9b0639e3df"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['THE', 'VERDICT', 'June', '1908', 'I', 'had', 'always', 'thought', 'Jack', 'Gisburn', 'rather', 'a', 'cheap', 'genius', '--', 'though', 'a', 'good', 'fellow', 'enough', '--', 'so', 'it', 'was', 'no', 'great', 'surprise', 'to', 'me', 'to']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(preprocessed))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0qbGC0cEYic",
        "outputId": "6f7279ec-aaba-4584-eec0-669bfb28a23a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**S2**: CREATING TOKEN IDS"
      ],
      "metadata": {
        "id": "3FwHYtbiEetN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_words = sorted(set(preprocessed)) #sort the words\n",
        "vocab_size = len(all_words) #length of words\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "id": "tztZf74DFvmT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92fd639c-80e2-4b4d-edff-e2bbfd3d6420"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1148\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab ={token: integer for integer, token in enumerate(all_words)}"
      ],
      "metadata": {
        "id": "3yuo3yCql20X"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i,item in enumerate(vocab.items()):\n",
        "  print(item)\n",
        "  if i>=50:\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gk3hCXQgTIwF",
        "outputId": "084d7f49-7573-4674-f153-17e72f77d278"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('!', 0)\n",
            "('\"', 1)\n",
            "(\"'\", 2)\n",
            "('(', 3)\n",
            "(')', 4)\n",
            "(',', 5)\n",
            "('--', 6)\n",
            "('.', 7)\n",
            "('1908', 8)\n",
            "(':', 9)\n",
            "(';', 10)\n",
            "('?', 11)\n",
            "('A', 12)\n",
            "('AM', 13)\n",
            "('Ah', 14)\n",
            "('Among', 15)\n",
            "('And', 16)\n",
            "('Are', 17)\n",
            "('Arrt', 18)\n",
            "('As', 19)\n",
            "('At', 20)\n",
            "('Be', 21)\n",
            "('Begin', 22)\n",
            "('Burlington', 23)\n",
            "('But', 24)\n",
            "('By', 25)\n",
            "('Carlo', 26)\n",
            "('Chicago', 27)\n",
            "('Claude', 28)\n",
            "('Come', 29)\n",
            "('Croft', 30)\n",
            "('Destroyed', 31)\n",
            "('Devonshire', 32)\n",
            "('Don', 33)\n",
            "('Dubarry', 34)\n",
            "('Emperors', 35)\n",
            "('End', 36)\n",
            "('FELT', 37)\n",
            "('Florence', 38)\n",
            "('For', 39)\n",
            "('Gallery', 40)\n",
            "('Gideon', 41)\n",
            "('Gisburn', 42)\n",
            "('Gisburns', 43)\n",
            "('Grafton', 44)\n",
            "('Greek', 45)\n",
            "('Grindle', 46)\n",
            "('Grindles', 47)\n",
            "('HAD', 48)\n",
            "('HAS', 49)\n",
            "('HAVE', 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r0gUUlZDTuqE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}